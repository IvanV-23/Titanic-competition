{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charge the data\n",
    "train_data_df = pd.read_csv(r'C:\\Repositorio\\Titanic competition\\Data\\train.csv')\n",
    "test_data_df = pd.read_csv(r'C:\\Repositorio\\Titanic competition\\Data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "Categorical variables:\n",
      "['Sex', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "#Prepare the data\n",
    "train_data_df.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)\n",
    "test_data_df.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)\n",
    "\n",
    "y = train_data_df['Survived']\n",
    "test_X = test_data_df\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_data_df, y, random_state = 0)\n",
    "train_X.drop(['Survived'], axis=1, inplace=True)\n",
    "val_X.drop(['Survived'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Obtener los tipos de datos categoricos\n",
    "s = (train_X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Apply one-hot encoding to each column with categorical data and reset index\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(test_X[object_cols]))\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = test_X.index\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(object_cols, axis=1)\n",
    "num_X_valid = val_X.drop(object_cols, axis=1)\n",
    "num_X_test = test_X.drop(object_cols, axis=1)\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "#Fill the dataframes NaN\n",
    "OH_X_train = OH_X_train.fillna(method='bfill', axis=0).fillna(0)\n",
    "OH_X_valid = OH_X_valid.fillna(method='bfill', axis=0).fillna(0)\n",
    "val_y = val_y.fillna(method='bfill', axis=0).fillna(0)\n",
    "train_y = train_y.fillna(method='bfill', axis=0).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#NOTA: HACER SEPARACION DE VALORES CATEGORICOS PARA OBETENER COLUMNA POR CADA UNA\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tvalidation_0-rmse:0.48747\n",
      "[1]\tvalidation_0-rmse:0.47581\n",
      "[2]\tvalidation_0-rmse:0.46484\n",
      "[3]\tvalidation_0-rmse:0.45473\n",
      "[4]\tvalidation_0-rmse:0.44593\n",
      "[5]\tvalidation_0-rmse:0.43789\n",
      "[6]\tvalidation_0-rmse:0.43095\n",
      "[7]\tvalidation_0-rmse:0.42411\n",
      "[8]\tvalidation_0-rmse:0.41827\n",
      "[9]\tvalidation_0-rmse:0.41269\n",
      "[10]\tvalidation_0-rmse:0.40764\n",
      "[11]\tvalidation_0-rmse:0.40322\n",
      "[12]\tvalidation_0-rmse:0.39922\n",
      "[13]\tvalidation_0-rmse:0.39580\n",
      "[14]\tvalidation_0-rmse:0.39240\n",
      "[15]\tvalidation_0-rmse:0.38943\n",
      "[16]\tvalidation_0-rmse:0.38702\n",
      "[17]\tvalidation_0-rmse:0.38416\n",
      "[18]\tvalidation_0-rmse:0.38162\n",
      "[19]\tvalidation_0-rmse:0.37937\n",
      "[20]\tvalidation_0-rmse:0.37709\n",
      "[21]\tvalidation_0-rmse:0.37557\n",
      "[22]\tvalidation_0-rmse:0.37450\n",
      "[23]\tvalidation_0-rmse:0.37346\n",
      "[24]\tvalidation_0-rmse:0.37185\n",
      "[25]\tvalidation_0-rmse:0.37049\n",
      "[26]\tvalidation_0-rmse:0.36960\n",
      "[27]\tvalidation_0-rmse:0.36764\n",
      "[28]\tvalidation_0-rmse:0.36710\n",
      "[29]\tvalidation_0-rmse:0.36600\n",
      "[30]\tvalidation_0-rmse:0.36577\n",
      "[31]\tvalidation_0-rmse:0.36502\n",
      "[32]\tvalidation_0-rmse:0.36496\n",
      "[33]\tvalidation_0-rmse:0.36449\n",
      "[34]\tvalidation_0-rmse:0.36402\n",
      "[35]\tvalidation_0-rmse:0.36360\n",
      "[36]\tvalidation_0-rmse:0.36343\n",
      "[37]\tvalidation_0-rmse:0.36247\n",
      "[38]\tvalidation_0-rmse:0.36222\n",
      "[39]\tvalidation_0-rmse:0.36177\n",
      "[40]\tvalidation_0-rmse:0.36186\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "#Select & fit a model\n",
    "titanic_model = XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
    "titanic_model.fit(OH_X_train, train_y,\n",
    "                  early_stopping_rounds=1,\n",
    "                  eval_set=[(OH_X_valid, val_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error: 0.2801858525171943\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model(XG_Boost model)\n",
    "\n",
    "predictions = titanic_model.predict(OH_X_valid)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(val_y,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0\n 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1\n 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0\n 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0\n 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n 0 0 1 0 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Create submission file\n",
    "final_prediction = titanic_model.predict(OH_X_test)#problema de orden??? reordenar columnas\n",
    "for numer_p,passenger in enumerate(final_prediction):\n",
    "    if passenger>0.5:\n",
    "        final_prediction[numer_p]=int(1)\n",
    "    else:\n",
    "        final_prediction[numer_p]=int(0)\n",
    "final_prediction = final_prediction.astype(int)\n",
    "gender_submission_df = pd.DataFrame()\n",
    "gender_submission_df['PassengerId'] = OH_X_test['PassengerId']\n",
    "gender_submission_df['Survived'] = final_prediction\n",
    "\n",
    "\n",
    "print(final_prediction)\n",
    "gender_submission_df.to_csv(r'C:\\Repositorio\\Titanic competition\\Results\\gender_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 8s 715ms/step - loss: 0.7843 - binary_accuracy: 0.5988 - val_loss: 0.6423 - val_binary_accuracy: 0.6816\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5389 - binary_accuracy: 0.7725 - val_loss: 0.6246 - val_binary_accuracy: 0.6771\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5558 - binary_accuracy: 0.7904 - val_loss: 0.6220 - val_binary_accuracy: 0.6682\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5439 - binary_accuracy: 0.7889 - val_loss: 0.6103 - val_binary_accuracy: 0.6771\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5033 - binary_accuracy: 0.8054 - val_loss: 0.5950 - val_binary_accuracy: 0.6816\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4839 - binary_accuracy: 0.8114 - val_loss: 0.5850 - val_binary_accuracy: 0.6951\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4890 - binary_accuracy: 0.7874 - val_loss: 0.5799 - val_binary_accuracy: 0.6996\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4459 - binary_accuracy: 0.8249 - val_loss: 0.5761 - val_binary_accuracy: 0.6996\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4430 - binary_accuracy: 0.8263 - val_loss: 0.5767 - val_binary_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4366 - binary_accuracy: 0.8114 - val_loss: 0.5778 - val_binary_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - binary_accuracy: 0.8144 - val_loss: 0.5802 - val_binary_accuracy: 0.6996\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4434 - binary_accuracy: 0.8219 - val_loss: 0.5840 - val_binary_accuracy: 0.6951\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4272 - binary_accuracy: 0.8308 - val_loss: 0.5882 - val_binary_accuracy: 0.6861\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4092 - binary_accuracy: 0.8413 - val_loss: 0.5935 - val_binary_accuracy: 0.6771\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4228 - binary_accuracy: 0.8204 - val_loss: 0.5977 - val_binary_accuracy: 0.6771\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4196 - binary_accuracy: 0.8234 - val_loss: 0.5997 - val_binary_accuracy: 0.6771\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3993 - binary_accuracy: 0.8323 - val_loss: 0.6041 - val_binary_accuracy: 0.6771\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4250 - binary_accuracy: 0.8249 - val_loss: 0.6102 - val_binary_accuracy: 0.6726\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model with Keras model\n",
    "\n",
    "#Define the  model\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu', input_shape=[12]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "#Add the cross-entropy loss & accuracy metric\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "#Fit the model\n",
    "history = model.fit(\n",
    "    OH_X_train, train_y,\n",
    "    validation_data=(OH_X_valid, val_y),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping],\n",
    "   # hide the output because we have so many epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.3414706 ]\n [0.34164828]\n [0.22304761]\n [0.5846433 ]\n [0.26053694]\n [0.32579562]\n [0.69423723]\n [0.5438819 ]\n [0.45015213]\n [0.3073522 ]\n [0.2706874 ]\n [0.36868635]\n [0.3279963 ]\n [0.40240481]\n [0.5874909 ]\n [0.37225825]\n [0.28606522]\n [0.25334895]\n [0.25333554]\n [0.36720765]\n [0.32868463]\n [0.7127599 ]\n [0.26817966]\n [0.3618184 ]\n [0.3360873 ]\n [0.5497807 ]\n [0.2601512 ]\n [0.34533703]\n [0.41135943]\n [0.31684548]\n [0.23892942]\n [0.34258038]\n [0.26864845]\n [0.34769624]\n [0.25038064]\n [0.35890257]\n [0.23359326]\n [0.3369795 ]\n [0.33367148]\n [0.25873134]\n [0.28145948]\n [0.27421498]\n [0.32586205]\n [0.25883776]\n [0.52555335]\n [0.3199016 ]\n [0.30420226]\n [0.57757986]\n [0.28426462]\n [0.29924107]\n [0.42900947]\n [0.3390622 ]\n [0.45170534]\n [0.2991704 ]\n [0.42379016]\n [0.38197836]\n [0.30439758]\n [0.24706665]\n [0.27180618]\n [0.23552564]\n [0.31908035]\n [0.22818142]\n [0.49183497]\n [0.42576793]\n [0.27719098]\n [0.24822578]\n [0.41188082]\n [0.34313127]\n [0.42728063]\n [0.52732605]\n [0.3619238 ]\n [0.3038961 ]\n [0.3703481 ]\n [0.30004573]\n [0.2869559 ]\n [0.33750358]\n [0.35014176]\n [0.33563215]\n [0.24875426]\n [0.34914875]\n [0.31490374]\n [0.29080248]\n [0.31305203]\n [0.31576872]\n [0.2730052 ]\n [0.6093482 ]\n [0.7726677 ]\n [0.28539371]\n [0.35570508]\n [0.5016107 ]\n [0.39391056]\n [0.3093677 ]\n [0.33194858]\n [0.46016908]\n [0.28714675]\n [0.26498187]\n [0.3034309 ]\n [0.19202447]\n [0.269722  ]\n [0.4885052 ]\n [0.21707737]\n [0.23904464]\n [0.30254966]\n [0.2469632 ]\n [0.25488734]\n [0.25393283]\n [0.37390244]\n [0.18473718]\n [0.3445397 ]\n [0.23449674]\n [0.21962085]\n [0.46836996]\n [0.3510856 ]\n [0.30194908]\n [0.31879845]\n [0.3763332 ]\n [0.30698004]\n [0.7655908 ]\n [0.2388542 ]\n [0.28621125]\n [0.37854254]\n [0.32143188]\n [0.30094522]\n [0.30792543]\n [0.27057198]\n [0.301489  ]\n [0.26150912]\n [0.25274962]\n [0.2333081 ]\n [0.27381533]\n [0.31137085]\n [0.2961638 ]\n [0.28704756]\n [0.30994213]\n [0.2827765 ]\n [0.314368  ]\n [0.19902626]\n [0.32009697]\n [0.24601415]\n [0.34074116]\n [0.29977214]\n [0.5358132 ]\n [0.30266094]\n [0.31942672]\n [0.42551196]\n [0.33038253]\n [0.294233  ]\n [0.33196127]\n [0.73566955]\n [0.24358287]\n [0.34894717]\n [0.36138815]\n [0.30725557]\n [0.2633229 ]\n [0.3881845 ]\n [0.31951654]\n [0.27919954]\n [0.22217295]\n [0.37539133]\n [0.38570666]\n [0.2937397 ]\n [0.29437417]\n [0.44639564]\n [0.23877692]\n [0.2619093 ]\n [0.29895172]\n [0.20689845]\n [0.28901953]\n [0.28256327]\n [0.30670905]\n [0.22827008]\n [0.5107836 ]\n [0.31481457]\n [0.33725291]\n [0.3810795 ]\n [0.27484167]\n [0.5718715 ]\n [0.29509276]\n [0.29580486]\n [0.27647913]\n [0.28928474]\n [0.3073185 ]\n [0.27690727]\n [0.2950433 ]\n [0.3172574 ]\n [0.29189   ]\n [0.2989843 ]\n [0.30826575]\n [0.27951783]\n [0.35203484]\n [0.30350965]\n [0.38451517]\n [0.38075274]\n [0.227317  ]\n [0.18744606]\n [0.31982085]\n [0.37858176]\n [0.3160838 ]\n [0.32402205]\n [0.20648864]\n [0.30880696]\n [0.29576987]\n [0.2073017 ]\n [0.36712497]\n [0.29591167]\n [0.25644916]\n [0.33617485]\n [0.26819974]\n [0.3495382 ]\n [0.21060023]\n [0.2828387 ]\n [0.29235864]\n [0.20399588]\n [0.36213315]\n [0.27743405]\n [0.3005633 ]\n [0.27340758]\n [0.33476466]\n [0.17092937]\n [0.62780845]\n [0.2963713 ]\n [0.68402046]\n [0.30174997]]\n"
     ]
    }
   ],
   "source": [
    "deep_predictions = model.predict(OH_X_valid)\n",
    "print(deep_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create submission file\n",
    "deep_predictions = titanic_model.predict(OH_X_test)#problema de orden??? reordenar columnas\n",
    "for numer_p,passenger in enumerate(deep_predictions):\n",
    "    if passenger>0.5:\n",
    "        deep_predictions[numer_p]=int(1)\n",
    "    else:\n",
    "        deep_predictions[numer_p]=int(0)\n",
    "deep_predictions = final_prediction.astype(int)\n",
    "gender_submission_df = pd.DataFrame()\n",
    "gender_submission_df['PassengerId'] = OH_X_test['PassengerId']\n",
    "gender_submission_df['Survived'] = deep_predictions\n",
    "\n",
    "\n",
    "gender_submission_df.to_csv(r'C:\\Repositorio\\Titanic competition\\Results\\Deep_Results\\gender_submission.csv', index=False)"
   ]
  }
 ]
}